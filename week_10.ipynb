{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2fe8792a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fe8792a",
        "outputId": "cb5b96c0-a4e6-4e9a-d81d-d249a022b11c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ale-py==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: gym-notices==0.0.7 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 2)) (0.0.7)\n",
            "Requirement already satisfied: ipykernel==6.15.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 3)) (6.15.1)\n",
            "Requirement already satisfied: opencv-python==4.6.0.66 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 4)) (4.6.0.66)\n",
            "Requirement already satisfied: pip-chill==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 7)) (0.0)\n",
            "Requirement already satisfied: stable-baselines3==1.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: tensorflow==2.9.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 9)) (2.9.1)\n",
            "Requirement already satisfied: wincertstore==0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 10)) (0.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py==0.7.5->-r requirement.txt (line 1)) (5.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ale-py==0.7.5->-r requirement.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from ale-py==0.7.5->-r requirement.txt (line 1)) (4.12.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (6.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (7.3.4)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (0.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (5.4.8)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (1.5.5)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (7.34.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel==6.15.1->-r requirement.txt (line 3)) (5.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->-r requirement.txt (line 7)) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.6.0->-r requirement.txt (line 8)) (1.3.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.6.0->-r requirement.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.6.0->-r requirement.txt (line 8)) (1.12.0+cu113)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.6.0->-r requirement.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3==1.6.0->-r requirement.txt (line 8)) (0.21.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (4.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.12)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (0.26.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.47.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1->-r requirement.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1->-r requirement.txt (line 9)) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.9.1->-r requirement.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->ale-py==0.7.5->-r requirement.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (0.18.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (3.0.30)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (0.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel==6.15.1->-r requirement.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel==6.15.1->-r requirement.txt (line 3)) (4.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel==6.15.1->-r requirement.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel==6.15.1->-r requirement.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (3.3.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->-r requirement.txt (line 9)) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.6.0->-r requirement.txt (line 8)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.6.0->-r requirement.txt (line 8)) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3==1.6.0->-r requirement.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3==1.6.0->-r requirement.txt (line 8)) (2022.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->-r requirement.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->-r requirement.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->-r requirement.txt (line 7)) (1.7.3)\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym import spaces, utils\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "!rm requirement.txt\n",
        "!echo -e \"ale-py==0.7.5 \\n gym-notices==0.0.7 \\n ipykernel==6.15.1 \\n opencv-python==4.6.0.66 \\n pip-chill==1.0.1 \\n pygame==2.1.0 \\n sklearn==0.0 \\n stable-baselines3==1.6.0 \\ntensorflow==2.9.1 \\n wincertstore==0.2\" >> requirement.txt\n",
        "!pip install -r requirement.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733e0850",
      "metadata": {
        "id": "733e0850"
      },
      "source": [
        "### Production Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "487594c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "487594c8",
        "outputId": "29af4f6e-e46a-48f7-e658-e91b8df7cfbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "env = pickle.load(open(\"model.pkl\", 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "07dcddaa",
      "metadata": {
        "id": "07dcddaa",
        "outputId": "7f55b980-f6fa-4055-f995-7286ccc8e6f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([597.80041667, 598.34933333, 600.06925   ])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "env.predict([[600,600,600,600,600,600,600,600,600,175],\n",
        "             [600,610,600,600,600,600,600,590,600,175],\n",
        "             [600,600,600,600,600,600,630,600,600,185]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3a75a12",
      "metadata": {
        "id": "c3a75a12"
      },
      "source": [
        "### Gym Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "12d87238",
      "metadata": {
        "id": "12d87238"
      },
      "outputs": [],
      "source": [
        "class HeatingFurnace(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        env initialization\n",
        "        \"\"\"\n",
        "        self.MAX_TEMP = 700\n",
        "        self.MIN_TEMP = 500\n",
        "        self.MAX_SPEED = 200\n",
        "        self.MIN_SPEED = 150\n",
        "        self.ADJUSTMENT_STEP = 10\n",
        "        self.NUM_ZONE = 9\n",
        "        self.TARGET = 685\n",
        "        self.SPEED_CONSUMPTION = 0.005\n",
        "        self.TEMP_CONSUMPTION = 0.01\n",
        "        self.STEP_PENALTY = -0.005\n",
        "\n",
        "        # smooth convergence\n",
        "        self.MAX_COST = self.MAX_TEMP*self.NUM_ZONE*self.TEMP_CONSUMPTION + \\\n",
        "                        self.MAX_SPEED*self.SPEED_CONSUMPTION\n",
        "\n",
        "        self.env = None # env model\n",
        "        self.obs = None # observation [the results of the temp and speed]\n",
        "        self.model_path = 'model.pkl'\n",
        "        self.steps = 0 # number of steps taken\n",
        "        self.total_steps = 0 # total number of steps taken\n",
        "        self.episodes = 0 # number of episodes\n",
        "        self.cumulative_reward = 0 # cumulative reward\n",
        "        self.episode_reward = 0 # reward for one episode\n",
        "        self.cost_list = [] # record for cost after episode\n",
        "        \n",
        "        # 20 discrete actions to either increase or decrease speed or zone temp\n",
        "        # 0-9 increase - 9 zones + 1 speed adjustment\n",
        "        # 10-19 decrease\n",
        "        self.action_space = spaces.Discrete((self.NUM_ZONE+1)*2)\n",
        "        \n",
        "        # continuous observation space including settings and output temp\n",
        "        low = [self.MIN_TEMP]*self.NUM_ZONE # define low range for observation space\n",
        "        low.append(self.MIN_SPEED) # speed\n",
        "        low.append(0) # output temp\n",
        "        \n",
        "        high = [self.MAX_TEMP]*self.NUM_ZONE # define high range for observation space\n",
        "        high.append(self.MAX_SPEED) # speed\n",
        "        high.append(self.MAX_TEMP) # output temp\n",
        "        \n",
        "        # define observation space with low and high boundary\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array(np.float16(low)),\n",
        "            high=np.array(np.float16(high)),\n",
        "            dtype=np.float16)\n",
        "\n",
        "    # step to take action\n",
        "    def step(self, action):\n",
        "        '''\n",
        "        for each step, take action\n",
        "        input:\n",
        "            action: (int) discrete action value\n",
        "        return:\n",
        "            obs: (ndarray) observation\n",
        "            reward: (float) reward from step\n",
        "            last: (bool) end episode signal\n",
        "            {}: (dict) debug use\n",
        "        '''\n",
        "        self.obs, reward, last = self.take_action(action) # take action\n",
        "        self.steps += 1 # increase episode step\n",
        "        self.total_steps += 1 # increase total training step\n",
        "        # if self.steps%1000 == 0:\n",
        "        #     print(f'step: {self.steps}')\n",
        "        #     print(f'cumulative reward: {self.cumulative_reward}')\n",
        "        #     print(f'avg reward per step: {self.cumulative_reward/self.steps}')\n",
        "        #     print(self.obs.tolist())\n",
        "        return self.obs, reward, last, {}\n",
        "\n",
        "\n",
        "    # reset environment [after ea episode reset env and update settings]\n",
        "    def reset(self):\n",
        "        '''\n",
        "        reset environment\n",
        "        return:\n",
        "            self.obs: (ndarray) observation\n",
        "        '''\n",
        "        if self.env is None: # initialize environment\n",
        "            self.env = self.init_env()\n",
        "        else: # log to terminal when reset episode\n",
        "            print(\"=================================\")\n",
        "            print(f\"episode summary: \")\n",
        "            print(f\"num episode: {self.episodes}\")\n",
        "            print(f\"num steps: {self.steps}\")\n",
        "            print(f\"episode reward: {self.episode_reward}\")\n",
        "            print(f\"per step reward: {self.episode_reward/self.steps}\")\n",
        "            print(f\"setting: {self.obs.tolist()}\")\n",
        "            print(f\"setting cost: {self.cost_list[-1]}\")\n",
        "            print(\"=================================\\n\")\n",
        "\n",
        "        # get initial observation after reset\n",
        "        setting = [] # reset setting\n",
        "        setting.extend(sorted(random.choices(range(self.MIN_TEMP, self.MAX_TEMP+1), k=self.NUM_ZONE))) # random init zone temp\n",
        "        setting.append(random.randrange(self.MIN_SPEED, self.MAX_SPEED+1)) # random init speed\n",
        "        self.obs = self.get_obs(setting, self.env) # get reset initial observation\n",
        "\n",
        "        # reset others\n",
        "        self.steps = 0 # reset episode step\n",
        "        self.episodes += 1 # increase episode number\n",
        "        self.episode_reward = 0 # reset episode reward\n",
        "\n",
        "        # return reset initial observation\n",
        "        return self.obs\n",
        "\n",
        "\n",
        "    # initialize env with model\n",
        "    def init_env(self):\n",
        "        '''\n",
        "        load pickle model and initiaze environment\n",
        "        return:\n",
        "            env: (sklearn model) sklearn model load from pickle binary file\n",
        "        '''\n",
        "        return pickle.load(open(self.model_path, 'rb'))\n",
        "\n",
        "\n",
        "    def get_obs(self, setting, env):\n",
        "        '''\n",
        "        based on the setting, get env observation\n",
        "        input:\n",
        "            setting: (list) setting for 9 heating zone and converyor speed\n",
        "        return:\n",
        "            obs: (ndarray) observation\n",
        "        '''\n",
        "        tval = env.predict([setting])[0] # get pieace temp from env based on setting\n",
        "        # TO COMPLETE!!!\n",
        "        # construct obs [contains 11 items, 11 settings: 9 heatzone and 1 belt speed and setting for 1 temp fo metal at the end]\n",
        "        setting = np.asarray(setting)\n",
        "        setting = np.append(setting, tval)\n",
        "        # setting = np.reshape(setting, (-1))\n",
        "        return (setting)\n",
        "\n",
        "\n",
        "    def take_action(self, action):\n",
        "        '''\n",
        "        take corresponding action based on action input\n",
        "        input:\n",
        "            action: (int) action number\n",
        "        return:\n",
        "            obs: (dnarray) observation\n",
        "            reward: (float) reward from step taken\n",
        "            last: (bool) end episode signal\n",
        "        '''\n",
        "        reward = 0 # define step reward\n",
        "        last = False # define last indicator\n",
        "\n",
        "        # reward += self.STEP_PENALTY # step penalty\n",
        "        setting = self.obs[:-1] # get last step settings\n",
        "        # increase zone temp\n",
        "        if action < self.NUM_ZONE-1:\n",
        "            adjusted = setting[action] + self.ADJUSTMENT_STEP # increase temp\n",
        "            if adjusted >= setting[action+1]: # if greater than next zone\n",
        "                setting[action] = setting[action+1] # equal to next\n",
        "            else:\n",
        "                setting[action] = adjusted # else equal to adjusted value\n",
        "        # increase last zone temp\n",
        "        elif action == self.NUM_ZONE-1: # if it is the last zone\n",
        "            adjusted = setting[action] + self.ADJUSTMENT_STEP # increase temp\n",
        "            if adjusted > self.MAX_TEMP: # if increased result greater than limit\n",
        "                setting[action] = self.MAX_TEMP # equal to limit\n",
        "            else:\n",
        "                setting[action] = adjusted # equal to adjusted value\n",
        "        # increase speed\n",
        "        elif action == self.NUM_ZONE:\n",
        "            adjusted = setting[action] + self.ADJUSTMENT_STEP # increase speed\n",
        "            if adjusted > self.MAX_SPEED: # if increased result greater than limit\n",
        "                setting[action] = self.MAX_SPEED # equal to limit\n",
        "            else:\n",
        "                setting[action] = adjusted # equal to adjusted value\n",
        "                \n",
        "        # decrease first zone temp\n",
        "        elif action == self.NUM_ZONE + 1:\n",
        "           # TO COMPLETE!!!\n",
        "           adjusted = setting[0] - self.ADJUSTMENT_STEP\n",
        "           if adjusted < self.MIN_TEMP:\n",
        "             setting[0] = self.MIN_TEMP\n",
        "           else:\n",
        "             setting[0] = adjusted\n",
        "\n",
        "        \n",
        "        # decrease zone temp\n",
        "        elif self.NUM_ZONE+1 < action and action < 19:\n",
        "            # TO COMPLETE!!!\n",
        "            adjusted = setting[action - 10] - self.ADJUSTMENT_STEP\n",
        "            if adjusted < self.MIN_TEMP:\n",
        "              setting[action - 10] = self.MIN_TEMP\n",
        "            elif adjusted > self.MAX_TEMP:\n",
        "              setting[action - 10] = self.MAX_TEMP\n",
        "            else:\n",
        "              setting[action - 10] = adjusted\n",
        "            \n",
        "        # decrease speed:\n",
        "        else:\n",
        "            # TO COMPLETE!!!\n",
        "            adjusted = setting[9] - self.ADJUSTMENT_STEP\n",
        "            if adjusted < self.MIN_SPEED:\n",
        "              setting[9] = self.MIN_SPEED\n",
        "            else:  \n",
        "              setting[9] = adjusted\n",
        "\n",
        "\n",
        "        # get observation based on new setting\n",
        "        obs = self.get_obs(setting, self.env)\n",
        "\n",
        "        # calculate reward\n",
        "        # TO COMPLETE!!!\n",
        "        prev_tval =  setting[-1]# get previous temp value\n",
        "        curr_tval =  obs[-1] #  get current temp value\n",
        "        prev_offset = prev_tval - self.TARGET # get absolute difference from prev temp to target value\n",
        "        curr_offset =  curr_tval - self.TARGET# get absolute difference from curr temp to target value\n",
        "        \n",
        "        # closer to target?\n",
        "        # if curr offset closer, positive reward & vice versa\n",
        "        reward += (prev_offset-curr_offset)/self.TARGET\n",
        "\n",
        "        # current temperature within end episode range\n",
        "        if self.TARGET-5 <= curr_tval and curr_tval <= self.TARGET+5:\n",
        "            reward += 1 # add episode reward\n",
        "            reward += self.evaluate_episode(setting)\n",
        "            last = True # indicate episode end\n",
        "\n",
        "        self.episode_reward += reward # increase episode reward\n",
        "        self.cumulative_reward += reward # increase cumulative reward\n",
        "\n",
        "        return np.array(obs), reward, last\n",
        "\n",
        "    def evaluate_episode(self, new_setting):\n",
        "        s = np.array(new_setting)\n",
        "        cost = 0\n",
        "        cost += np.sum(s[:self.NUM_ZONE]*self.TEMP_CONSUMPTION)\n",
        "        cost += s[-1]*self.SPEED_CONSUMPTION\n",
        "        # delta = (self.last_cost - cost)\n",
        "        self.cost_list.append(cost)\n",
        "        normalized_score = -cost/self.MAX_COST\n",
        "        return normalized_score\n",
        "\n",
        "\n",
        "    def set_obs(self, obs):\n",
        "        self.obs = obs\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        '''\n",
        "        close environment\n",
        "        '''\n",
        "        self.env = None # reset env to None\n",
        "\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        '''\n",
        "        render environment info\n",
        "        '''\n",
        "        if self.steps%1000 == 0:\n",
        "            print(f'step: {self.steps}')\n",
        "            print(f'cumulative reward: {self.cumulative_reward}')\n",
        "            print(f'avg reward per step: {self.cumulative_reward/self.steps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab9abd1",
      "metadata": {
        "id": "5ab9abd1"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "978df180",
      "metadata": {
        "id": "978df180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3960727-6174-4b60-832a-b7ae1afa0e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "=================================\n",
            "episode summary: \n",
            "num episode: 1\n",
            "num steps: 8\n",
            "episode reward: -6.015661237834557\n",
            "per step reward: -0.7519576547293196\n",
            "setting: [531.0, 537.0, 525.0, 571.0, 587.0, 639.0, 645.0, 679.0, 700.0, 150.0, 686.5966666666669]\n",
            "setting cost: 54.89\n",
            "=================================\n",
            "\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2       |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | -2.18    |\n",
            "|    value_loss         | 1.86     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 8         |\n",
            "|    ep_rew_mean        | -6.02     |\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.81     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -2.88     |\n",
            "|    value_loss         | 1.03      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.56    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -1.8     |\n",
            "|    value_loss         | 0.758    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.14    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -0.666   |\n",
            "|    value_loss         | 0.336    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.9     |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -0.42    |\n",
            "|    value_loss         | 0.0611   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 8         |\n",
            "|    ep_rew_mean        | -6.02     |\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.18     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -0.329    |\n",
            "|    value_loss         | 0.0296    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 80       |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 43       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.19    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.00985  |\n",
            "|    value_loss         | 4.05e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 81       |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 48       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.15    |\n",
            "|    explained_variance | 4.35e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.00727  |\n",
            "|    value_loss         | 1.23e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 82       |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 54       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.09    |\n",
            "|    explained_variance | 1.71e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.000825 |\n",
            "|    value_loss         | 1.91e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 83       |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 60       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.08    |\n",
            "|    explained_variance | 3.93e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.00585  |\n",
            "|    value_loss         | 7.51e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 83       |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 66       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2       |\n",
            "|    explained_variance | 2.33e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.00197  |\n",
            "|    value_loss         | 1.26e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 83       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 71       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2       |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 1.39e-06 |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 83       |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 77       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.96    |\n",
            "|    explained_variance | 0.000402 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.000565 |\n",
            "|    value_loss         | 1.3e-07  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 84       |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 83       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 3.03e-05 |\n",
            "|    value_loss         | 6.4e-10  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 84       |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 88       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.66    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 7.04e-07 |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 84       |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 94       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.5     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.0135   |\n",
            "|    value_loss         | 0.000157 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 99       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 1.42e-06 |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 105      |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 1.23e-06 |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 110      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 6.66e-07 |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 8        |\n",
            "|    ep_rew_mean        | -6.02    |\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 116      |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.48    |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 2.12e-06 |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x7fcd778071d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from stable_baselines3 import A2C # RL algorithms # TO COMPLETE!!!\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "newEnv = HeatingFurnace()\n",
        "model = A2C('MlpPolicy', newEnv, verbose=1)\n",
        "model.learn(total_timesteps=10000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7aa92d",
      "metadata": {
        "id": "8c7aa92d"
      },
      "source": [
        "###### https://stable-baselines.readthedocs.io/en/master/guide/install.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c89ea4fc",
      "metadata": {
        "id": "c89ea4fc"
      },
      "source": [
        "#### Vectorize customized environment and learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "bf4fa03f",
      "metadata": {
        "id": "bf4fa03f"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE!!!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vecEnv = make_vec_env(HeatingFurnace, n_envs=4)\n",
        "model = A2C('MlpPolicy', vecEnv, verbose=1)\n",
        "model.learn(total_timesteps=25000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYdYNs8dYv2l",
        "outputId": "772614e1-9144-44c3-99db-4b4ee22e306c"
      },
      "id": "OYdYNs8dYv2l",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "episode summary: \n",
            "num episode: 1\n",
            "num steps: 59\n",
            "episode reward: -38.5031446624088\n",
            "per step reward: -0.652595672244217\n",
            "setting: [542.0, 502.0, 562.0, 555.0, 620.0, 625.0, 615.0, 688.0, 690.0, 200.0, 684.6410833333339]\n",
            "setting cost: 54.99\n",
            "=================================\n",
            "\n",
            "=================================\n",
            "episode summary: \n",
            "num episode: 1\n",
            "num steps: 72\n",
            "episode reward: -53.4884419403893\n",
            "per step reward: -0.7428950269498514\n",
            "setting: [583.0, 563.0, 615.0, 620.0, 640.0, 630.0, 666.0, 689.0, 689.0, 150.0, 687.5111666666668]\n",
            "setting cost: 57.7\n",
            "=================================\n",
            "\n",
            "=================================\n",
            "episode summary: \n",
            "num episode: 2\n",
            "num steps: 17\n",
            "episode reward: -12.042835697992697\n",
            "per step reward: -0.7084020998819234\n",
            "setting: [510.0, 542.0, 542.0, 552.0, 563.0, 626.0, 626.0, 686.0, 690.0, 171.0, 684.4128333333334]\n",
            "setting cost: 54.224999999999994\n",
            "=================================\n",
            "\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.3      |\n",
            "|    ep_rew_mean        | -34.7     |\n",
            "| time/                 |           |\n",
            "|    fps                | 78        |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.54     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | -3.02     |\n",
            "|    value_loss         | 1.59      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.3      |\n",
            "|    ep_rew_mean        | -34.7     |\n",
            "| time/                 |           |\n",
            "|    fps                | 84        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.61     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -1.77     |\n",
            "|    value_loss         | 0.664     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 49.3     |\n",
            "|    ep_rew_mean        | -34.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 69       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.22    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -1.26    |\n",
            "|    value_loss         | 0.298    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 49.3     |\n",
            "|    ep_rew_mean        | -34.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 88       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 90       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.19    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -0.847   |\n",
            "|    value_loss         | 0.208    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.3      |\n",
            "|    ep_rew_mean        | -34.7     |\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 112       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.36     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -0.578    |\n",
            "|    value_loss         | 0.0757    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.3      |\n",
            "|    ep_rew_mean        | -34.7     |\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 134       |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.58     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -0.236    |\n",
            "|    value_loss         | 0.0122    |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 49.3     |\n",
            "|    ep_rew_mean        | -34.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 156      |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.49    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.0242   |\n",
            "|    value_loss         | 0.000119 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 49.3     |\n",
            "|    ep_rew_mean        | -34.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 89       |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 178      |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.36    |\n",
            "|    explained_variance | 5.96e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.0158   |\n",
            "|    value_loss         | 4.97e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 49.3     |\n",
            "|    ep_rew_mean        | -34.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 199      |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.3     |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.0054   |\n",
            "|    value_loss         | 6.33e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 49.3     |\n",
            "|    ep_rew_mean        | -34.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 221      |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -2.01    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.000509 |\n",
            "|    value_loss         | 0.000161 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.3      |\n",
            "|    ep_rew_mean        | -34.7     |\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 243       |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.93     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -0.00676  |\n",
            "|    value_loss         | 0.000509  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 49.3     |\n",
            "|    ep_rew_mean        | -34.7    |\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 265      |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -1.8     |\n",
            "|    explained_variance | 1        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 1.33e-06 |\n",
            "|    value_loss         | 0        |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.a2c.a2c.A2C at 0x7fcd02373190>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = HeatingFurnace()\n",
        "obs = e.reset()\n",
        "for i in range(10000):\n",
        "    action, _state = model.predict(obs)\n",
        "    obs, reward, done, a = e.step(action)\n",
        "    e.render()\n",
        "    print(obs[-1])\n",
        "    if done:\n",
        "      obs = e.reset()\n",
        "      break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEZGwUFpDBjv",
        "outputId": "3fd3e38c-1b56-4482-d47b-540525724cfa"
      },
      "id": "uEZGwUFpDBjv",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696.9805000000005\n",
            "696.9805000000005\n",
            "696.9805000000005\n",
            "696.9805000000005\n",
            "696.9805000000005\n",
            "696.9805000000005\n",
            "696.9805000000005\n",
            "696.4316666666672\n",
            "696.4316666666672\n",
            "696.4316666666672\n",
            "697.0483333333336\n",
            "697.0483333333336\n",
            "690.6145000000002\n",
            "690.6145000000002\n",
            "690.6145000000002\n",
            "690.6145000000002\n",
            "690.6145000000002\n",
            "687.562916666667\n",
            "=================================\n",
            "episode summary: \n",
            "num episode: 1\n",
            "num steps: 18\n",
            "episode reward: -14.185007922749405\n",
            "per step reward: -0.7880559957083002\n",
            "setting: [500.0, 558.0, 584.0, 584.0, 604.0, 646.0, 670.0, 697.0, 677.0, 150.0, 687.562916666667]\n",
            "setting cost: 55.95\n",
            "=================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TnIojnaPKHod"
      },
      "id": "TnIojnaPKHod",
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gym",
      "language": "python",
      "name": "gym"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "week 10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}